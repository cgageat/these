\appendix

\part*{Annexes}
\addcontentsline{toc}{chapter}{Annexes}

\chapter{Calcul du gradient de la fonctionnelle}
Afin d'améliorer la lisibilité, nous nous affranchirons dans ces annexes de $(\boldsymbol{r},\Omega)$. Nous remplacerons donc $\rho(\boldsymbol{r},\Omega)$ par $\rho$, $\phi(\boldsymbol{r},\Omega)$ par $\phi$ et $\gamma(\boldsymbol{r},\Omega)$ par $\gamma$.
\label{chap:annexes:grad}

\section{Fonctionnelle idéale}
\label{sec:annexes:grad:id}
\begin{eqnarray}
\beta \delta \mathcal{F}_\mathrm{id}[\rho] &=& \beta \mathcal{F}_\mathrm{id}[\rho + \delta \rho] -\beta \mathcal{F}_\mathrm{id}[\rho] \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ [\rho + \delta \rho]\ln(\frac{\rho + \delta \rho}{\rho_0})- [\Delta\rho + \delta \rho] \\
& & - \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \rho\ln(\frac{\rho}{\rho_0})-\Delta\rho \nonumber \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \rho \ln(\frac{\rho + \delta \rho}{\rho_0}) + \delta \rho\ln(\frac{\rho + \delta \rho}{\rho_0}) - \Delta\rho - \delta\rho \\
& & - \rho\ln(\frac{\rho}{\rho_0}) + \Delta\rho \nonumber \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \rho \ln(\frac{\rho + \delta \rho}{\rho_0}) + \delta \rho\ln(\frac{\rho + \delta \rho}{\rho_0}) - \delta\rho - \rho\ln(\frac{\rho}{\rho_0})\nonumber
\end{eqnarray}
Or
\begin{eqnarray}
\ln(\frac{\rho + \delta \rho}{\rho_0}) = \ln(\frac{\rho + \delta \rho}{\rho}\frac{\rho}{\rho_0}) = \ln(\frac{\rho + \delta \rho}{\rho})+\ln(\frac{\rho}{\rho_0}) = \ln(1+\frac{\delta \rho}{\rho})+\ln(\frac{\rho}{\rho_0})
\end{eqnarray}
Et, comme $\frac{\delta \rho}{\rho}$ tend vers 0, il est possible de faire le développement de Taylor de $\ln(1+\frac{\delta \rho}{\rho})$ qui nous donne:
\begin{eqnarray}
\ln(1+\frac{\delta \rho}{\rho}) = \frac{\delta \rho}{\rho} + \mathcal{O}(\delta\rho^{2})
\end{eqnarray}
On injecte ce développement l'équation précédente:
\begin{eqnarray}
\beta \delta \mathcal{F}_\mathrm{id}[\rho] &=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \rho \ln(\frac{\rho + \delta \rho}{\rho_0})  + \delta \rho\ln(\frac{\rho + \delta \rho}{\rho_0}) - \delta\rho - \rho\ln(\frac{\rho}{\rho_0})\\
& & + \mathcal{O}(\delta\rho^{2}) \nonumber \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \rho [\frac{\delta \rho}{\rho} + \ln(\frac{\rho}{\rho_0})] + \delta \rho[\frac{\delta \rho}{\rho} + \ln(\frac{\rho}{\rho_0})] - \delta\rho \\
& & - \rho\ln(\frac{\rho}{\rho_0}) + \mathcal{O}(\delta\rho^{2}) \nonumber \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \delta\rho + \rho \ln(\frac{\rho}{\rho_0}) + \frac{\delta \rho^2}{\rho} + \delta \rho \ln(\frac{\rho}{\rho_0}) - \delta\rho \\
& & - \rho\ln(\frac{\rho}{\rho_0}) + \mathcal{O}(\delta\rho^{2}) \nonumber \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \delta \rho \ln(\frac{\rho}{\rho_0}) + \mathcal{O}(\delta\rho^{2})
\end{eqnarray}
On obtient finalement:
\boitesimple{
\begin{eqnarray}
\beta \frac{\delta \mathcal{F}_\mathrm{id}[\rho]}{\delta \rho} &=& \ln(\frac{\rho}{\rho_0})
\end{eqnarray}
}

Le gradient de la partie idéale s'annule en $\rho=\rho_0$. Cette partie tend donc vers un système homogène de densité $\rho_0$.


\section{Fonctionnelle extérieure}
\label{sec:annexes:grad:ext}
\begin{eqnarray}
\delta \mathcal{F}_\mathrm{ext}[\rho] &=& \mathcal{F}_\mathrm{ext}[\rho + \delta \rho] -\mathcal{F}_\mathrm{ext}[\rho] \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ (\rho+\delta\rho)\phi - \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \rho\phi  \\
&=& \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \delta\rho\phi
\end{eqnarray}
On obtient finalement:
\boitesimple{
\begin{eqnarray}
\beta \frac{\delta \mathcal{F}_\mathrm{ext}[\rho]}{\delta \rho} &=& \phi
\end{eqnarray}
}

On voit ici que la partie idéale favorisera une faible densité pour une valeur élevée de potentiel $\phi$ et des densités fortes pour des valeurs de potentiels faibles.

\section{Fonctionnelle d'excès}
\label{sec:annexes:grad:exc}
\begin{eqnarray}
\beta \delta \mathcal{F}_\mathrm{exc}[\rho] &=& \beta \mathcal{F}_\mathrm{exc}[\rho + \delta \rho, \rho^\prime] -\beta \mathcal{F}_\mathrm{exc}[\rho, \rho^\prime] \\
& & + \beta \mathcal{F}_\mathrm{exc}[\rho, \rho^\prime + \delta \rho^\prime] -\beta \mathcal{F}_\mathrm{exc}[\rho, \rho^\prime] \nonumber\\
&=& 2 \beta \mathcal{F}_\mathrm{exc}[\rho + \delta \rho, \rho^\prime] - 2 \beta \mathcal{F}_\mathrm{exc}[\rho, \rho^\prime] \\
&=& -\int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ (\Delta\rho+\delta\rho) \gamma  + \int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ (\Delta\rho \gamma) \\
&=& -\int\mathrm{d}\boldsymbol{r}\mathrm{d}\Omega\ \delta\rho \gamma
\end{eqnarray}
On obtient finalement:
\boitesimple{
\begin{eqnarray}
\beta\frac{\delta \mathcal{F}_\mathrm{exc}[\rho]}{\delta \rho} = - \gamma
\end{eqnarray}
}

\section{Fonctionnelle de bridge}
\label{sec:annexes:grad:bridge}
\begin{eqnarray}
\hat{\rho}(\vec{k})&=&HT[\rho(\vec{r})]  \\
\bar{\hat{\rho}}(\vec{k})&=&\hat{\rho}(\vec{k})K(\vec{k})   \\
\bar{\rho}(\vec{r})&=&HT^{-1}[\bar{\hat{\rho}}(\vec{k})]  \\
\Delta\bar{\rho}(\vec{r})&=&\bar{\rho}(\vec{r})-\rho_{0}  \\
\bar{F}_{b}[\rho(\vec{r})]&=&A\delta\bar{\rho}(\vec{r})^{3}+B\bar{\rho}(\vec{r})^{2}\delta\bar{\rho}(\vec{r})^{4}  \\
\frac{\delta\bar{F}_{b}[\rho(\vec{r})]}{\delta\rho(\vec{r})}&=&3A\delta\bar{\rho}(\vec{r})^{2}+2B\bar{\rho}(\vec{r})\delta\bar{\rho}(\vec{r})^{4}+4B\bar{\rho}(\vec{r})^{2}\delta\bar{\rho}(\vec{r})^{3}  \\
\frac{\delta\bar{\hat{F}}_{b}[\rho(\vec{r})]}{\delta\rho(\vec{r})}&=&HT[\frac{\delta\bar{F}_{b}[\rho(\vec{r})]}{\delta\rho(\vec{r})}]  \\
\frac{\delta\hat{F}_{b}[\rho(\vec{r})]}{\delta\rho(\vec{r})}&=&\frac{\delta\bar{\hat{F}}_{b}[\rho(\vec{r})]}{\delta\bar{\rho}(\vec{r})}K(\vec{k})  \\
\frac{\delta F_{b}[\rho(\vec{r})]}{\delta\rho(\vec{r})}&=&HT^{-1}\frac{\delta\hat{F}_{b}[\rho(\vec{r})]}{\delta\rho(\vec{r})} 
\end{eqnarray}
%\chapter{Implémentations}
%\label{chap:annexes:implementations}

%\cleardoublepage
%\section{Implémentation naïve de la fonction de Lennard-Jones}
%\label{sec:annexes:implementations:MJ_naive}
%\lstinputlisting[basicstyle=\scriptsize, language=Fortran, caption={Implémentation naïve de la fonction de Lennard-Jones.}, label={code:lannard_jones_naive},captionpos=b, breaklines=true]{annexes/lennard_jones_naive.f90}

%\cleardoublepage
%\section{Implémentation optimisée de la fonction de Lennard-Jones}
%\label{sec:annexes:implementations:MJ_opti}
%\lstinputlisting[basicstyle=\scriptsize, language=Fortran, caption={Implémentation optimisée de la fonction de Lennard-Jones.}, label={code:lannard_jones_naive},captionpos=b, breaklines=true]{annexes/lennard_jones_opti.f90}

%\cleardoublepage
%\section{Implémentation du minimiseur steepest descent}
%\label{sec:annexes:implementations:sd}
%\lstinputlisting[basicstyle=\scriptsize, language=Fortran, caption={Implémentation optimisée de la fonction de Lennard-Jones.}, label={code:lannard_jones_naive},captionpos=b, breaklines=true]{annexes/steepest_descent.f90}




\chapter{Mesures statistiques}
\label{chap:annexes:stats}

Cinq mesures statistiques sont disponibles avec \textit{MDFT Database Tool} pour quantifier les performances de la dynamique moléculaire ou de MDFT: l'erreur quadratique moyenne RMSE, le $\mathrm{P}_{\mathrm{bias}}$ ainsi que 3 coefficients de corrélation: Pearson R, Spearman $\rho$ et Kendall $\tau$.

\paragraph{Root-mean-squared error (RMSE)} correspond à la racine de l'erreur quadratique moyenne. Cette métrique permet de mesurer la différence entre les valeurs calculées et les valeurs de référence. Elle est définie comme:

\begin{equation}
    RMSE = \sqrt{MSE} = \sqrt{\frac{\sum_i{(\hat{y}_i-y_i)^2}}{n}}
\end{equation}

\noindent avec $\hat{y}_i$ la valeur calculée, $y_i$ la valeur de référence et n la taille de l'échantillon.

\paragraph{Le coefficient de corrélation de Pearson ($R$)} la corrélation linéaire entre deux variables $X$ et $Y$. Il est définit comme

\begin{equation}
    R = \frac{cov(X,Y)}{\sigma_X \sigma_Y}
\end{equation}

\noindent avec $cov(X,Y)=E[(X-E[X])(Y-E(Y))]$ la covariance entre $X$ et $Y$, $\sigma_X$ et $\sigma_Y$ la déviation standard de $X$ et $Y$. $R$ varie entre -1 and 1. La magnitude de $|R|$ mesure la qualité de la corrélation linéraire et le signe de $R$ correspond au signe de la pente. Le coefficient de détermination $R^2$ généralement utilisé correspond au carré du coefficient $R$ de Perason.

\paragraph{Le coefficient de corrélation de rang de Spearman ($\rho$)}  mesure le dépendance statistique non paramétrique entre deux variables $X$ and $Y$. Il est utilisé lorsque deux variables statistiques semblent corrélées sans que la relation entre les deux variables soit de type affine. Pour y parvenir, il calcule le coefficient de corrélation entre les rangs des différentes valeurs et non entre les valeurs elles mêmes. Il est définit comme :

\begin{equation}
    \rho = \frac{cov(rg_X,rg_Y)}{\sigma_{rg_X} \sigma_{rg_Y}}
\end{equation}

\noindent avec $cov(rg_X,rg_Y)$ la covariance entre les rangs des variables $rg_X$ et $rg_Y$ et $\sigma_{rg_X}$ et $\sigma_{rg_Y}$ la déviation standard des rangs de ces variables. 

\paragraph{Le coefficient de corrélation de Kendall ($\tau$)}  est une autre mesure basée sur le rang des valeurs. Il est définit comme:

\begin{equation}
    \tau = \frac{n_{con}-n_{dis}}{n(n-1)/2}
\end{equation}

\noindent avec $n_{con}$ le nombre de paires concordantes, $n_{dis}$ le nombre de paires discordantes et $n$ le nombre de pairs total. Lorsque de l'étude de chaque paire possible $[(X_i,Y_i)(X_j,Y_j)]$, on compte concordant toute paire respectant $Y_i>Y_j$ si $X_i>X_j$ ou $Y_i<Y_j$ si $X_i<X_j$. Les autres paires sont comptées discordantes.


\paragraph{Le pourcentage de biais ($P_{bias}$)}, exprimé en pourcentage, mesure la tendance moyenne relative des valeurs calculées à être supérieures ou inférieures aux valeurs de référence. Il est définit comme:

\begin{equation}
    P_{bias} = \frac{\sum_i(Y_{i}^{obs}-Y_{i}^{sim})*100}{\sum_i(Y_{i}^{obs})}
\end{equation}

\noindent avec $Y_{i}^{sim}$ les valeurs calculées et $Y_{i}^{obs}$ les valeurs de référence. Une valeur de biais positive indique que le modèle à tendance à surestimer les valeurs calculées alors qu'une valeur négative indique que les valeurs sont sous-estimées.
